{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBM409 Assignment 1 - Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbor Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    "Assume that you have a large training dataset. Specify a disadvantage of the kNearest Neighbor method when using it during testing. State also your reason\n",
    "about your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing will be expensive when dataset is growing. Because program have to search through all dataset for every test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "Create a 1-Dimensional classification dataset in which the 1-Nearest Neighbors\n",
    "method always gives a leave-one out cross validation error value of 1 (In other\n",
    "words, the method can’t guess correct class for a specific point in the dataset ).\n",
    "State also a proper explanation about your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+-+<br/>\n",
    "Because whichever class you choose to leave out, the linear boundary classiffication will be wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "What is the class appointed to the test instance for K=1? State also reason behind your answer.<br/>\n",
    "What is the class appointed to the test instance for K=3? State also reasonbehind your answer.<br/>\n",
    "What is the class appointed to the test instance for K=5? State also reason\n",
    "behind your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For K = 1, test instance will be '-'. Because the closest neighbor is '-'.<br/>\n",
    "For K = 3, test instance will be '-'. Because two of the closest neighbors are '-' and one of them is '+'.<br/>\n",
    "For K = 5, test instance will be '+'. Because three of the closest neighbors are '+' and two of them are '-'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4:\n",
    "If all instances of the data have the same scale then k-Nearest Neighbor’s performance increases drastically.<br/>\n",
    "Answer: True\n",
    "\n",
    "While k-Nearest Neighbor performs well with a small number of input variables, it’s performance decreases when the number of inputs becomes large.<br/>\n",
    "Answer: True\n",
    "\n",
    "k-Nearest Neighbor makes no assumption about the functional form of the problem it handles.<br/>\n",
    "Answer: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    " Assume that you have five students have registered to a class and the class have a midterm and the final exam. You have obtained a set of their marks on two exams, which is in the table below:<br/>\n",
    " Student 1: Midterm Exam -> 87, Midter Exam (Squared) -> 7569, Final Exam -> 94<br/>\n",
    " Student 2: Midterm Exam -> 70, Midter Exam (Squared) -> 4900, Final Exam -> 72<br/>\n",
    " Student 3: Midterm Exam -> 92, Midter Exam (Squared) -> 8464, Final Exam -> 85<br/>\n",
    " Student 4: Midterm Exam -> 67, Midter Exam (Squared) -> 4489, Final Exam -> 76<br/>\n",
    " Student 5: Midterm Exam -> 45, Midter Exam (Squared) -> 2025, Final Exam -> 56<br/>\n",
    "You plan to a model which form’s is $ f_θ(x) = θ_0 + θ_1x_1 + θ_2x_2 $ for fitting the data above. The $ x_1 $ shows midterm exam score while $ x_2 $ shows square of the midterm score. Besides you plan to use feature scaling (using divide operation by the ”maxmin”, or range, of a feature) and mean normalization. What is the normalized value of the feature $ x_2^{(4)} $?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x_2^{(4)} = {\\frac {x - average(x)}{max(x) - min(x)}} = {\\frac {4489 - 5484,4}{8464 - 2025}} = -0,155\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question2:\n",
    "Which of the offsets (vertical offsets or perpendicular offsets) used in linear regressions least square line fit? Assume that horizontal axis represents independent variable and vertical axis represents dependent variable. State your answer with your proper explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertical offsets are used in linear regressions least square line fit. Because residual must be considered for vertical offsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "Considering the table below, consisting of four training examples:<br/>\n",
    "x -> 1, 2, 4, 0<br/>\n",
    "y -> 0.5, 1, 2, 0<br/>\n",
    "Assume that you are trying to fit the data above to the linear regression model $ f_θ(x) = θ_0 + θ_1x_1 $. Find the $ θ_0 $ and $ θ_1 $ values by using closed form solution $ (θ = (X^T X)^−1 X^T y) $. Also state dimension values of $ X $, $ y $ and $ θ $ matrices. Finally show your calculations step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ X = \n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 4 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}, This matrix 4x2 $$<br/>\n",
    "$$ X^T = \n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 2 & 4 & 0\n",
    "\\end{bmatrix},   This matrix 2x4 $$<br/>\n",
    "$$ y = \n",
    "\\begin{bmatrix}\n",
    "0.5 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "0\n",
    "\\end{bmatrix}, This matrix 4x1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ θ = (X^T X)^{−1} X^T y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ X^T X =  \n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 2 & 4 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 4 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "4 & 7 \\\\\n",
    "7 & 21\n",
    "\\end{bmatrix},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(X^T X)^{-1} = \n",
    "\\begin{bmatrix}\n",
    "3/5 & -1/5 \\\\\n",
    "-1/5 & 4/5\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ θ = (X^T X)^{−1} X^T y $$<br/>\n",
    "$$   = \\begin{bmatrix}\n",
    "3/5 & -1/5 \\\\\n",
    "-1/5 & 4/5\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 2 & 4 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0.5 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "2/5 & 1/5 & -1/5 & 3/5 \\\\\n",
    "-3/5 & 1/35 & 9/35 & -1/5\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0.5 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "0\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1/2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$ θ_0 = 0, θ_1 = 1/2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4:\n",
    "State a valid reason for feature scaling and explain why it is a valid reason with respect to your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply feature scaling to independent values when preparing our data before processing. It is for normalising the data within a particular range. We apply feature scaling in KNN Algorith, because it is a distance metric algorith."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, I developed a system that estimates movie ratings based similarities between users. I used optionally weighted or not weighted K-Nearest Neighbors method. Besides I used K-Fold Cross Validation method while testing and improving my method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Numpy and Pandas libraries are used for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"mae\" function calculates the mean absolute error of estimations. $$ MAE = 1/n \\sum_{i=1}^{n} |d_i - \\hat{d}_i| $$\n",
    "test variable expects a pandas library's dataframe which stores test data, movie_matrix variable is a also a dataframe and it is a matrix of user and movie Ids with data of rating. Also weighted value decides that model will be KNN or weighted KNN.\n",
    "Function takes specific rating from test data and predicts rating for that data. Then it calculates mean absolute value of these datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(test, movie_matrix, weighted=False):\n",
    "    total = 0\n",
    "    movieIndexTest = test['movieId']\n",
    "    userIndexTest = test['userId']\n",
    "\n",
    "    for i in test.index:\n",
    "        diff = test['rating'][i] - predict(movieIndexTest[i], userIndexTest[i], movie_matrix, weighted)\n",
    "        total += abs(diff)\n",
    "    return total / len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"predict\" function predicts the rating, as the name implies, of userIndex user's for movieIndex movie. movie_matrix is a pandas library's dataframe which holds data of movieId, userId and ratings. weighted parameter decides that model will be KNN or weighted KNN. knnVal decides how many  neighbors will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(movieIndex, userIndex, movie_matrix, weighted, knnVal=8):\n",
    "    distances = distances_dict[userIndex]\n",
    "    no_neighbor = True\n",
    "    i = 0\n",
    "    k_nearest_ratings = list()\n",
    "    while i < len(distances) and knnVal > 0:\n",
    "        if movie_matrix.loc[movieIndex, distances[i][1]] != 0:\n",
    "            no_neighbor = False\n",
    "            knnVal -= 1\n",
    "            k_nearest_ratings.append(movie_matrix.loc[movieIndex, distances[i][1]])\n",
    "        i += 1\n",
    "    if no_neighbor:\n",
    "        return 0\n",
    "    return get_knn_value(k_nearest_ratings, knnVal, weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"get_knn_value\" function calculates the final predict value from data in k_nearest_ratings list that holds the values of nearest neighbors. knnVal variable holds the number of neighbors. weighted parameter is for deciding the model will be KNN or weighted KNN.\n",
    "If weighted is True the function gives the more number weights to the closer neighbors. Otherwise all neighbors will have the same importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_value(k_nearest_ratings, knnVal, weighted):\n",
    "    if weighted:\n",
    "        L = list()\n",
    "        total_weight = 0\n",
    "        for i in k_nearest_ratings:\n",
    "            L.append(i * knnVal)\n",
    "            total_weight += knnVal\n",
    "            knnVal -= 1\n",
    "        return sum(L) / total_weight\n",
    "    else:\n",
    "        d = dict()\n",
    "        count = 0\n",
    "        for i in k_nearest_ratings:\n",
    "            d[i] = d.get(i, 0) + 1\n",
    "            if d[i] > count:\n",
    "                count = d[i]\n",
    "\n",
    "        # checking for ties\n",
    "        tie_list = set()\n",
    "        for i in d:\n",
    "            if count == d[i]:\n",
    "                tie_list.add(i)\n",
    "\n",
    "        return sum(tie_list) / len(tie_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"get_ordered_distances\" function returns a list of tuples which contains similarity value of parameter userIndex to a user and the user's id. The function also sorts the list with respect to similarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_distances(userIndex):\n",
    "    userIdList = movie_matrix.columns\n",
    "    distances = list()\n",
    "    for i in userIdList:\n",
    "        if i == userIndex:\n",
    "            continue\n",
    "        distances.append((cos_sim(movie_matrix.loc[:, i], movie_matrix.loc[:, userIndex]), i))\n",
    "    distances.sort(key=lambda tup: tup[0], reverse=True)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes 2 vectors x, y and calculates the formula: $$ cos(\\pmb x, \\pmb y) = \\frac {\\pmb x \\cdot \\pmb y}{||\\pmb x|| \\cdot ||\\pmb y||} $$\n",
    "and returns the cosine similarity of x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(x, y):\n",
    "    dot_product = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    return dot_product / (norm_x * norm_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"split_data_into_k\" function takes dataset parameter which is a pandas library's dataframe and splits it into k pieces. These pieces are put into a list and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_k(k, dataset):\n",
    "    kfold = list()\n",
    "    length = len(dataset) - 1\n",
    "\n",
    "    for i in range(k):\n",
    "        kfold.append(dataset[round(i*(length/k)):round((i+1)*(length/k))])\n",
    "    return kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20    # decides k Fold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code part reads .csv file and forms necessary dataframes using pandas library\n",
    "ratings_data = pd.read_csv(\"ratings_train.csv\")\n",
    "ratings_data = ratings_data.sample(frac=1, random_state=300)\n",
    "movie_matrix = ratings_data.pivot_table(index='movieId', columns='userId', values='rating')\n",
    "movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_list = split_data_into_k(k, ratings_data)    # Splitting data inko k part for k_fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances_dict holds the data of distances between users each other\n",
    "distances_dict = dict()\n",
    "for i in movie_matrix.columns:\n",
    "    distances_dict[i] = get_ordered_distances(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To implement K-Fold validation, splitted data is divided into test and training parts\n",
    "# For each repetition, one part of the splitted data is going to be test data and the other parts are going to be training.\n",
    "# And each step calculates the Mean Absolute Error for divided parts.\n",
    "for i in range(k):\n",
    "    test = kfold_list[i]\n",
    "    # forming train data\n",
    "    frames = list()\n",
    "    for j in range(k):\n",
    "        if j != i:\n",
    "            frames.append(kfold_list[j][:])\n",
    "\n",
    "    train = pd.concat(frames)\n",
    "    print('Mean Absolute Error for', i+1, 'fold:', mae(test, movie_matrix, weighted=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For K value in KFold: 10 and K value for Weighted - KNN: 7, output of Mean absolute error will be: <br/>\n",
    "Mean Absolute Error for 1 fold: 0.8880752634858354<br/>\n",
    "Mean Absolute Error for 2 fold: 0.8788219713483412<br/>\n",
    "Mean Absolute Error for 3 fold: 0.8896792095231325<br/>\n",
    "Mean Absolute Error for 4 fold: 0.8941935092258501<br/>\n",
    "Mean Absolute Error for 5 fold: 0.8630064945913649<br/>\n",
    "Mean Absolute Error for 6 fold: 0.8831680406364072<br/>\n",
    "Mean Absolute Error for 7 fold: 0.8882125151803193<br/>\n",
    "Mean Absolute Error for 8 fold: 0.8770697981454463<br/>\n",
    "Mean Absolute Error for 9 fold: 0.8762623845474355<br/>\n",
    "Mean Absolute Error for 10 fold: 0.9038520488801689<br/>\n",
    "For K value in KFold: 10 and K value for KNN: 7, output of Mean absolute error will be:<br/>\n",
    "Mean Absolute Error for 1 fold: 0.9205000602603252<br/>\n",
    "Mean Absolute Error for 2 fold: 0.9067124374711218<br/>\n",
    "Mean Absolute Error for 3 fold: 0.9186015252557724<br/>\n",
    "Mean Absolute Error for 4 fold: 0.9315061063795601<br/>\n",
    "Mean Absolute Error for 5 fold: 0.9122310504851645<br/>\n",
    "Mean Absolute Error for 6 fold: 0.9164214406234946<br/>\n",
    "Mean Absolute Error for 7 fold: 0.9325052560394228<br/>\n",
    "Mean Absolute Error for 8 fold: 0.9081937302480055<br/>\n",
    "Mean Absolute Error for 9 fold: 0.9149545305395398<br/>\n",
    "Mean Absolute Error for 10 fold: 0.9366866530076599<br/>\n",
    "<br/>\n",
    "For K value in KFold: 5 and K value for Weighted - KNN: 3, output of Mean absolute error will be: <br/>\n",
    "Mean Absolute Error for 1 fold: 0.9281234619981718<br/>\n",
    "Mean Absolute Error for 2 fold: 0.9392400168728924<br/>\n",
    "Mean Absolute Error for 3 fold: 0.9121317584194636<br/>\n",
    "Mean Absolute Error for 4 fold: 0.923276387326584<br/>\n",
    "Mean Absolute Error for 5 fold: 0.9349574632637252<br/>\n",
    "For K value in KFold: 5 and K value for KNN: 3, output of Mean absolute error will be: <br/>\n",
    "Mean Absolute Error for 1 fold: 0.920486770254751<br/>\n",
    "Mean Absolute Error for 2 fold: 0.939644263217095<br/>\n",
    "Mean Absolute Error for 3 fold: 0.9116571749982395<br/>\n",
    "Mean Absolute Error for 4 fold: 0.9245934101987215<br/>\n",
    "Mean Absolute Error for 5 fold: 0.9263985563289485"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
